{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higgs dataset preprocessing\n",
    "\n",
    "From the paper:\n",
    "\n",
    "[M. De Domenico, A. Lima, P. Mougel and M. Musolesi. The Anatomy of a Scientific Rumor. (Nature Open Access) Scientific Reports 3, 2980 (2013).](http://www.nature.com/srep/2013/131018/srep02980/full/srep02980.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/ubuntu/data/higgs/\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Customize plot colors for dark backgrounds\n",
    "%matplotlib inline\n",
    "mpl.rcParams['axes.edgecolor'] = 'grey'\n",
    "mpl.rcParams['grid.color'] = '#66CCCC'\n",
    "mpl.rcParams['text.color'] = '#0EBFE9'\n",
    "mpl.rcParams['xtick.color'] = '#66CCCC'\n",
    "mpl.rcParams['ytick.color'] = '#66CCCC'\n",
    "mpl.rcParams['axes.labelcolor'] = '#0EBFE9'\n",
    "\n",
    "import IPython.utils.path\n",
    "DATA_DIR = os.path.join(IPython.utils.path.get_home_dir(), 'data/higgs/')\n",
    "print 'Data directory:', DATA_DIR\n",
    "dataset_name = 'higgs'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_layered_graph(input_df, freq=1, unit='min', action='RT', social_graph=None):\n",
    "    \n",
    "    def round_df(df, freq, unit):\n",
    "        mul = 1\n",
    "        if unit == 'min':\n",
    "            mul = 60\n",
    "            unit = 'Min'\n",
    "            \n",
    "        elif unit == 'hour':\n",
    "            mul = 60 * 60\n",
    "            unit = 'H'\n",
    "            \n",
    "        elif unit == 'day':\n",
    "            mul = 60 * 60 * 24\n",
    "            unit = 'D'\n",
    "        else:\n",
    "            mul = 1\n",
    "            unit = 'S'\n",
    "        \n",
    "        ns_min = freq * mul * 1000000000\n",
    "        idx = pd.DatetimeIndex(((df.index.astype(np.int64) // ns_min) * ns_min))\n",
    "        df.index = idx\n",
    "        return df, unit\n",
    "\n",
    "\n",
    "    def create_layers(df, freq, unit):\n",
    "        # Trick: use pandas resample to generate continuous indexes\n",
    "        dfR = df.resample(str(freq) + unit) \n",
    "        layer_map = dict(itertools.izip(dfR.index.astype(np.int64), itertools.count()))\n",
    "        df['layer'] = np.vectorize(lambda x: layer_map[x])(df.index.astype(np.int64))\n",
    "        # delta between layers (timedelta)\n",
    "        delta = dfR.index[1] - dfR.index[0]\n",
    "        return df, delta\n",
    "\n",
    "    \n",
    "    h = nx.DiGraph()\n",
    "    h.name = 'Higgs layered ' + action + ' - ' + str(freq) + ' ' + unit\n",
    "    \n",
    "    df = input_df.copy()\n",
    "    if action != '' and action is not None:\n",
    "        df = df[df['action'] == action]\n",
    "    \n",
    "    df, unit = round_df(df, freq, unit)\n",
    "    df, delta_ts = create_layers(df, freq, unit)\n",
    "    # Maximum id in whole dataframe, min should not be 0\n",
    "    max_id = np.max(np.max(df[['src_id', 'tgt_id']]).values)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        base_src = row['src_id']\n",
    "        base_tgt = row['tgt_id']\n",
    "        layer = row['layer']\n",
    "        act = row['action']\n",
    "        \n",
    "        if act == 'RT':  # invert edges\n",
    "            base_src, base_tgt = base_tgt, base_src\n",
    "        \n",
    "        src = base_src + (layer * max_id)\n",
    "        tgt = base_tgt + ((layer + 1) * max_id)\n",
    "        \n",
    "        # Add nodes\n",
    "        h.add_node(src, {'base_id': base_src, 'layer': layer, 'timestamp': idx})\n",
    "        h.add_node(tgt, {'base_id': base_tgt, 'layer': layer + 1, 'timestamp': idx + delta_ts})\n",
    "        \n",
    "        # Add edge\n",
    "        e_d = {'action': act, 'timestamp': idx}\n",
    "        if social_graph is not None:\n",
    "            if social_graph.has_edge(base_src, base_tgt):\n",
    "                e_d['is_social'] = True\n",
    "            else:\n",
    "                e_d['is_social'] = False\n",
    "            \n",
    "        h.add_edge(src, tgt, e_d)\n",
    "        \n",
    "    return h, df\n",
    "\n",
    "\n",
    "def extract_components(h):\n",
    "    components = filter(lambda x: x.number_of_edges() >= 1 and x.number_of_nodes() >= 2, \n",
    "                    nx.weakly_connected_component_subgraphs(h))\n",
    "    res = []\n",
    "    for i, comp in enumerate(components):\n",
    "        comp.name = i\n",
    "        res.append({'component': comp})\n",
    "        \n",
    "    df = pd.DataFrame(res)\n",
    "    df.index.name = 'component_id'\n",
    "    return df\n",
    "\n",
    "\n",
    "def enrich_components(df, with_social=False):\n",
    "    \n",
    "    def get_period_span(c):\n",
    "        ts = sorted(nx.get_node_attributes(c, 'timestamp').values())\n",
    "        return (ts[0], ts[-1])\n",
    "    \n",
    "    def get_social_edge_ratio(c):\n",
    "        social_edges = sum(nx.get_edge_attributes(c, 'is_social').values())  # True == 1, False 0\n",
    "        return social_edges / float(c.number_of_edges())\n",
    "        \n",
    "    df['node_count'] = df['component'].apply(lambda x: x.number_of_nodes())\n",
    "    df['edge_count'] = df['component'].apply(lambda x: x.number_of_edges())\n",
    "    df['height'] = df['component'].apply(lambda x: len(np.unique(nx.get_node_attributes(x, 'base_id').values())))\n",
    "    df['width'] = df['component'].apply(lambda x: len(np.unique(nx.get_node_attributes(x, 'layer').values())))\n",
    "    period_series = df['component'].apply(get_period_span)\n",
    "    df['start'] = period_series.apply(lambda x: x[0])\n",
    "    df['end'] = period_series.apply(lambda x: x[1])\n",
    "    df['social_ratio'] = df['component'].apply(get_social_edge_ratio)\n",
    "    \n",
    "    return df.sort('node_count', ascending=False)\n",
    "\n",
    "\n",
    "def create_activated_components(input_df, freq=1, unit='min', action='RT', social_graph=None):\n",
    "    h, _ = create_layered_graph(input_df, freq, unit, action, social_graph)\n",
    "    comp_df = extract_components(h)\n",
    "    with_social = True if social_graph is not None else False\n",
    "    return enrich_components(comp_df, with_social)\n",
    "\n",
    "\n",
    "def create_graph_from_activity(activity_df, action='RT'):\n",
    "    g = nx.DiGraph()\n",
    "    df = activity_df[activity_df['action'] == action]\n",
    "    g.name = 'Higgs ' + action\n",
    "    for idx, d in df.iterrows():\n",
    "        src = d['src_id']\n",
    "        tgt = d['tgt_id']\n",
    "        if not g.has_edge(src, tgt):\n",
    "            g.add_edge(src, tgt, weight=1)\n",
    "        else:\n",
    "            g[src][tgt]['weight'] += 1\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACTIVITY = pd.read_csv(os.path.join(DATA_DIR, 'HiggsDiscovery_multiplex_time.txt'), \n",
    "                       sep=' ', header=None, names=['src_id', 'tgt_id', 'timestamp', 'action'],\n",
    "                       dtype={'src_id': np.int64, 'tgt_id': np.int64, 'timestamp': np.int64, 'action': str},\n",
    "                       index_col=2)\n",
    "\n",
    "ACTIVITY['action'] = ACTIVITY['action'].astype(str)\n",
    "ACTIVITY.index = pd.to_datetime(ACTIVITY.index.values * 1e9)\n",
    "ACTIVITY.index.name = 'timestamp'\n",
    "# G = create_graph_from_activity(ACTIVITY, 'RT')\n",
    "# print nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Higgs RE\n",
      "Type: DiGraph\n",
      "Number of nodes: 39940\n",
      "Number of edges: 33728\n",
      "Average in degree:   0.8445\n",
      "Average out degree:   0.8445\n"
     ]
    }
   ],
   "source": [
    "G = create_graph_from_activity(ACTIVITY, 'RE')\n",
    "print nx.info(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse retweet graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retweet graph loaded in: 9.10212087631\n",
      "Name: Higgs RT\n",
      "Type: DiGraph\n",
      "Number of nodes: 257827\n",
      "Number of edges: 334208\n",
      "Average in degree:   1.2962\n",
      "Average out degree:   1.2962\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# path = os.path.join(DATA_DIR, 'HiggsDiscovery_RT.edges.gz')\n",
    "# RETWEET = nx.read_edgelist(path, create_using=nx.DiGraph(),\n",
    "#                            nodetype=int, data=(('weight', int),))\n",
    "# RETWEET.name = 'Higgs RT'\n",
    "# nx.write_gpickle(RETWEET, os.path.join(DATA_DIR, 'retweet.gpickle'))\n",
    "RETWEET = nx.read_gpickle(os.path.join(DATA_DIR, 'retweet.gpickle'))\n",
    "print 'Retweet graph loaded in:', time.time() - start\n",
    "print nx.info(RETWEET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse mention graph    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mention graph loaded in: 7.37287902832\n",
      "Name: Higgs MT\n",
      "Type: DiGraph\n",
      "Number of nodes: 118659\n",
      "Number of edges: 156371\n",
      "Average in degree:   1.3178\n",
      "Average out degree:   1.3178\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# MENTION = nx.read_edgelist(os.path.join(DATA_DIR, 'HiggsDiscovery_MT.edges.gz'), \n",
    "#                            create_using=nx.DiGraph(), nodetype=int, data=(('weight', int),))\n",
    "# MENTION.name = 'Higgs MT'\n",
    "# nx.write_gpickle(MENTION, os.path.join(DATA_DIR, 'mention.gpickle'))\n",
    "\n",
    "MENTION = nx.read_gpickle(os.path.join(DATA_DIR, 'mention.gpickle'))\n",
    "print 'Mention graph loaded in:', time.time() - start\n",
    "print nx.info(MENTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse reply graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply graph loaded in: 1.68447113037\n",
      "Name: Higgs RE\n",
      "Type: DiGraph\n",
      "Number of nodes: 39940\n",
      "Number of edges: 33728\n",
      "Average in degree:   0.8445\n",
      "Average out degree:   0.8445\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# REPLY = nx.read_edgelist(os.path.join(DATA_DIR, 'HiggsDiscovery_RE.edges.gz'),\n",
    "#                          create_using=nx.DiGraph(), nodetype=int, data=(('weight', int),))\n",
    "# REPLY.name = 'Higgs RE'\n",
    "# nx.write_gpickle(REPLY, os.path.join(DATA_DIR, 'reply.gpickle'))\n",
    "\n",
    "REPLY = nx.read_gpickle(os.path.join(DATA_DIR, 'reply.gpickle'))\n",
    "print 'Reply graph loaded in:', time.time() - start\n",
    "print nx.info(REPLY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse social network (follower network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social graph loaded in: 56.2548730373\n",
      "Name: Higgs SOCIAL\n",
      "Type: DiGraph\n",
      "Number of nodes: 456626\n",
      "Number of edges: 14855842\n",
      "Average in degree:  32.5339\n",
      "Average out degree:  32.5339\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# SOCIAL = nx.read_edgelist(os.path.join(DATA_DIR, 'HiggsDiscovery_social.edges.gz'),\n",
    "#                           create_using=nx.DiGraph(), nodetype=int, )\n",
    "# SOCIAL.name = 'Higgs SOCIAL'\n",
    "# nx.write_gpickle(SOCIAL, os.path.join(DATA_DIR, 'social.gpickle'))\n",
    "\n",
    "SOCIAL = nx.read_gpickle(os.path.join(DATA_DIR, 'social.gpickle'))\n",
    "print 'Social graph loaded in:', time.time() - start\n",
    "print nx.info(SOCIAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "\n",
    "- Period I: Before the announcement on 2nd July, there were some rumors about the discovery of a Higgs-like boson at Tevatron;\n",
    "\n",
    "\n",
    "- Period II: On 2nd July at 1 PM GMT, scientists from CDF and D0 experiments, based at Tevatron, presented results indicating that the Higgs particle should have a mass between 115 and 135 GeV/c2 (corresponding to about 123-144 times the mass of the proton) [7];\n",
    "\n",
    "\n",
    "- Period III: After 2nd July and before 4th of July there were many rumors about the Higgs boson dis- covery at LHC [8];\n",
    "\n",
    "\n",
    "- Period IV: The main event was the announce- ment on 4th July at 8 AM GMT by the scientists from the ATLAS and CMS experiments, based at CERN, presenting results indicating the existence of a new particle, compatible with the Higgs bo- son, with mass around 125 GeV/c2 [9, 10]. After 4th July, popular media covered the event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract causal multilayer graph activated components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COMPS = create_activated_components(ACTIVITY, 10, 'min', '', SOCIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>social_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>  6.125000</td>\n",
       "      <td>  5.250000</td>\n",
       "      <td>  5.500000</td>\n",
       "      <td> 2.250000</td>\n",
       "      <td> 0.411458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01</th>\n",
       "      <td> 10.413655</td>\n",
       "      <td>  9.465863</td>\n",
       "      <td>  9.883534</td>\n",
       "      <td> 2.369478</td>\n",
       "      <td> 0.279677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-02</th>\n",
       "      <td>  9.417594</td>\n",
       "      <td>  8.546006</td>\n",
       "      <td>  8.645096</td>\n",
       "      <td> 2.570273</td>\n",
       "      <td> 0.266949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-03</th>\n",
       "      <td> 10.301187</td>\n",
       "      <td>  9.510386</td>\n",
       "      <td>  9.425816</td>\n",
       "      <td> 2.571217</td>\n",
       "      <td> 0.268098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-04</th>\n",
       "      <td> 18.600016</td>\n",
       "      <td> 18.862885</td>\n",
       "      <td> 14.073494</td>\n",
       "      <td> 2.490950</td>\n",
       "      <td> 0.250973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-05</th>\n",
       "      <td>  8.474138</td>\n",
       "      <td>  7.564815</td>\n",
       "      <td>  7.989783</td>\n",
       "      <td> 2.487069</td>\n",
       "      <td> 0.237692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-06</th>\n",
       "      <td>  7.230906</td>\n",
       "      <td>  6.416075</td>\n",
       "      <td>  6.520426</td>\n",
       "      <td> 2.461812</td>\n",
       "      <td> 0.316567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-07</th>\n",
       "      <td>  6.278409</td>\n",
       "      <td>  5.388258</td>\n",
       "      <td>  5.796402</td>\n",
       "      <td> 2.417614</td>\n",
       "      <td> 0.308414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-08</th>\n",
       "      <td>  5.968051</td>\n",
       "      <td>  5.127796</td>\n",
       "      <td>  5.335463</td>\n",
       "      <td> 2.402556</td>\n",
       "      <td> 0.314654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-09</th>\n",
       "      <td>  7.926027</td>\n",
       "      <td>  7.156164</td>\n",
       "      <td>  7.126027</td>\n",
       "      <td> 2.484932</td>\n",
       "      <td> 0.344522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-10</th>\n",
       "      <td>  6.432773</td>\n",
       "      <td>  5.626050</td>\n",
       "      <td>  5.533613</td>\n",
       "      <td> 2.474790</td>\n",
       "      <td> 0.375901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            node_count  edge_count     height     width  social_ratio\n",
       "start                                                                \n",
       "2012-06-30    6.125000    5.250000   5.500000  2.250000      0.411458\n",
       "2012-07-01   10.413655    9.465863   9.883534  2.369478      0.279677\n",
       "2012-07-02    9.417594    8.546006   8.645096  2.570273      0.266949\n",
       "2012-07-03   10.301187    9.510386   9.425816  2.571217      0.268098\n",
       "2012-07-04   18.600016   18.862885  14.073494  2.490950      0.250973\n",
       "2012-07-05    8.474138    7.564815   7.989783  2.487069      0.237692\n",
       "2012-07-06    7.230906    6.416075   6.520426  2.461812      0.316567\n",
       "2012-07-07    6.278409    5.388258   5.796402  2.417614      0.308414\n",
       "2012-07-08    5.968051    5.127796   5.335463  2.402556      0.314654\n",
       "2012-07-09    7.926027    7.156164   7.126027  2.484932      0.344522\n",
       "2012-07-10    6.432773    5.626050   5.533613  2.474790      0.375901"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILT_COMPS = COMPS[COMPS['node_count'] > 3]\n",
    "C = FILT_COMPS.set_index('start', drop=False).sort_index()\n",
    "C.resample('1D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap between retweet and social network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of overlap ( Higgs RT , Higgs SOCIAL ): 59.1912820758\n",
      "Number of common edges: 197822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59.191282075833016, 197822)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlap_graph(g1, g2):\n",
    "    common_edges = 0\n",
    "    for u, v in g1.edges_iter():\n",
    "        if g2.has_edge(u, v):\n",
    "            common_edges += 1\n",
    "\n",
    "    res = common_edges * 100 / float(nx.number_of_edges(g1))\n",
    "    print 'Percentage of overlap (', g1.name, ',', g2.name, '):', res\n",
    "    print 'Number of common edges:', common_edges\n",
    "    return res, common_edges\n",
    "\n",
    "# overlap_graph(REPLY, SOCIAL)\n",
    "overlap_graph(RETWEET, SOCIAL)\n",
    "# overlap_graph(MENTION, SOCIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
